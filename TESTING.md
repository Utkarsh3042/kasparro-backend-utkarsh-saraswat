# üß™ Testing Instructions

## **Prerequisites**

1. ‚úÖ All code changes implemented
2. ‚úÖ CoinPaprika API key added to `.env` file
3. ‚úÖ Docker Desktop installed and running
4. ‚úÖ Virtual environment activated (for local testing)

---

## **üîπ Step 1: Generate Sample CSV Data**

```powershell
# Navigate to project root
cd C:\Users\bossu\OneDrive\Desktop\assignment\backend-etl-system

# Activate virtual environment
venv\Scripts\activate

# Generate sample CSV
python scripts\generate_sample_csv.py
```

**Expected Output:**
```
‚úÖ Sample CSV created successfully!
üìÅ Location: data\crypto_data.csv
üìä Total rows: 10
```

**Verify CSV file exists:**
```powershell
Get-Content data\crypto_data.csv | Select-Object -First 5
```

---

## **üîπ Step 2: Test Locally (Without Docker)**

### **2.1 Install Dependencies**

```powershell
# Make sure venv is activated
pip install -r requirements.txt
pip install -e .
```

### **2.2 Run the Application**

```powershell
uvicorn src.main:app --reload
```

**Expected startup logs:**
```
üöÄ Crypto ETL Backend System Starting...
üì¶ Version: 2.0.0
‚ú® Features: CSV + API Ingestion, Normalization, Auto-Start ETL
üîó Sources: CSV, CoinGecko, CoinPaprika
‚úÖ Auto-ingested X records from CSV
‚úÖ Auto-ingested Y records from CoinGecko
```

### **2.3 Test Health Endpoint**

**In a new PowerShell window:**

```powershell
(Invoke-WebRequest -Uri "http://localhost:8000/health" -UseBasicParsing).Content | ConvertFrom-Json | ConvertTo-Json -Depth 10
```

**Expected Response:**
```json
{
  "status": "healthy",
  "version": "2.0.0",
  "data": {
    "total_records": 150
  },
  "features": {
    "csv_ingestion": true,
    "api_ingestion": true,
    "normalization": true,
    "deduplication": true,
    "auto_ingest": true
  }
}
```

### **2.4 Test CSV Ingestion**

```powershell
Invoke-WebRequest -Uri "http://localhost:8000/api/v1/ingest/csv?limit=10" -Method POST -UseBasicParsing | Select-Object -Expand Content
```

**Expected Response:**
```json
{
  "status": "success",
  "message": "Ingested 10 records from CSV",
  "count": 10,
  "normalized": true,
  "total_unique_coins": 160
}
```

### **2.5 Test Data Retrieval**

```powershell
# Get first 5 records
(Invoke-WebRequest -Uri "http://localhost:8000/api/v1/data?page=1&page_size=5" -UseBasicParsing).Content | ConvertFrom-Json | ConvertTo-Json -Depth 10
```

**Verify:**
- ‚úÖ Records have `canonical_id` field
- ‚úÖ No duplicate coins (same symbol appears only once)
- ‚úÖ Data from multiple sources

### **2.6 Test Statistics**

```powershell
(Invoke-WebRequest -Uri "http://localhost:8000/api/v1/stats" -UseBasicParsing).Content | ConvertFrom-Json | ConvertTo-Json -Depth 10
```

**Verify:**
- ‚úÖ `total_coins` matches unique count
- ‚úÖ `top_gainers` and `top_losers` present
- ‚úÖ Market cap and volume calculated

---

## **üîπ Step 3: Test with Docker**

### **3.1 Stop Local Server**

Press `Ctrl+C` in the terminal running uvicorn

### **3.2 Build and Start Docker Services**

```powershell
# Using PowerShell script (recommended)
.\run.ps1 build
.\run.ps1 up

# OR using docker-compose directly
docker-compose build
docker-compose up -d
```

**Expected Output:**
```
‚úÖ Building Docker images...
‚úÖ Starting services...
üìç API: http://localhost:8000
üìñ Docs: http://localhost:8000/docs
```

### **3.3 Check Service Status**

```powershell
.\run.ps1 status

# OR
docker-compose ps
```

**Expected:**
```
NAME                   STATUS       PORTS
crypto-etl-backend    Up 30 sec    0.0.0.0:8000->8000/tcp
crypto-etl-db         Up 30 sec    0.0.0.0:5432->5432/tcp
```

### **3.4 View Logs**

```powershell
.\run.ps1 logs

# OR
docker-compose logs -f backend
```

**Look for:**
```
üöÄ Crypto ETL Backend System Starting...
‚úÖ Auto-ingested X records from CSV
‚úÖ Auto-ingested Y records from CoinGecko
‚úÖ Auto-ingested Z records from CoinPaprika
üéâ Auto-ingest completed: 150 unique coins stored
```

### **3.5 Test Auto-Ingestion Worked**

```powershell
(Invoke-WebRequest -Uri "http://localhost:8000/health" -UseBasicParsing).Content | ConvertFrom-Json
```

**Verify:**
- ‚úÖ `total_records > 0` (data was auto-ingested)
- ‚úÖ `last_updated` is recent
- ‚úÖ All features are `true`

### **3.6 Test PostgreSQL Connection**

```powershell
# Connect to PostgreSQL
docker exec -it crypto-etl-db psql -U crypto_user -d crypto_etl

# Inside PostgreSQL shell:
\dt                           # List tables
SELECT * FROM cryptocurrencies LIMIT 5;
SELECT * FROM source_mappings LIMIT 5;
\q                           # Exit
```

---

## **üîπ Step 4: Test All Endpoints**

### **Option A: Use Interactive API Docs (Recommended)**

1. Open browser: **http://localhost:8000/docs**
2. Test each endpoint:
   - `GET /health` ‚Üí Click "Try it out" ‚Üí "Execute"
   - `POST /api/v1/ingest/csv` ‚Üí Try it out
   - `POST /api/v1/ingest/coingecko` ‚Üí Try it out
   - `POST /api/v1/ingest/coinpaprika` ‚Üí Try it out
   - `POST /api/v1/ingest/all` ‚Üí Try it out
   - `GET /api/v1/data` ‚Üí Try with filters
   - `GET /api/v1/stats` ‚Üí View statistics

### **Option B: Use PowerShell Commands**

```powershell
# Test CSV ingestion
Invoke-WebRequest -Uri "http://localhost:8000/api/v1/ingest/csv" -Method POST -UseBasicParsing

# Test CoinGecko ingestion
Invoke-WebRequest -Uri "http://localhost:8000/api/v1/ingest/coingecko?limit=50" -Method POST -UseBasicParsing

# Test CoinPaprika ingestion
Invoke-WebRequest -Uri "http://localhost:8000/api/v1/ingest/coinpaprika?limit=30" -Method POST -UseBasicParsing

# Test ingest all
Invoke-WebRequest -Uri "http://localhost:8000/api/v1/ingest/all" -Method POST -UseBasicParsing

# Get data with filters
Invoke-WebRequest -Uri "http://localhost:8000/api/v1/data?source=csv&page_size=5" -UseBasicParsing
Invoke-WebRequest -Uri "http://localhost:8000/api/v1/data?symbol=BTC" -UseBasicParsing

# Get statistics
Invoke-WebRequest -Uri "http://localhost:8000/api/v1/stats" -UseBasicParsing
```

---

## **üîπ Step 5: Test Normalization & Deduplication**

### **5.1 Ingest from Multiple Sources**

```powershell
# Clear existing data and ingest from all sources
Invoke-WebRequest -Uri "http://localhost:8000/api/v1/ingest/all" -Method POST -UseBasicParsing
```

### **5.2 Verify Deduplication**

```powershell
# Get all Bitcoin records
(Invoke-WebRequest -Uri "http://localhost:8000/api/v1/data?symbol=BTC" -UseBasicParsing).Content | ConvertFrom-Json
```

**Expected:**
- ‚úÖ Only ONE Bitcoin record (despite multiple sources)
- ‚úÖ Record has `canonical_id: "btc"`
- ‚úÖ Source is highest priority (coingecko > coinpaprika > csv)

### **5.3 Check Total Unique Coins**

```powershell
$response = (Invoke-WebRequest -Uri "http://localhost:8000/api/v1/data" -UseBasicParsing).Content | ConvertFrom-Json
$response.total
```

**Expected:**
- ‚úÖ Count is less than (CSV records + CoinGecko records + CoinPaprika records)
- ‚úÖ Proves deduplication is working

---

## **üîπ Step 6: Run Automated Tests**

### **6.1 Run Tests Locally**

```powershell
# Activate venv
venv\Scripts\activate

# Run all tests
pytest -v

# Run with coverage
pytest --cov=src --cov-report=html

# View coverage
start htmlcov\index.html
```

### **6.2 Run Tests in Docker**

```powershell
.\run.ps1 test

# OR
docker-compose run --rm backend pytest -v
```

**Expected:**
```
tests/test_api.py::test_health_check PASSED
tests/test_api.py::test_get_data_empty PASSED
==================== 2 passed in 0.45s ====================
```

---

## **üîπ Step 7: Verify All Critical Gates PASS**

### **‚úÖ Module 0.1 - CSV Gate**
```powershell
# Test CSV ingestion
Invoke-WebRequest -Uri "http://localhost:8000/api/v1/ingest/csv" -Method POST -UseBasicParsing
```
**Pass criteria:** CSV data ingested successfully

### **‚úÖ Module 0.2 - Hardcoded Secrets Gate**
```powershell
# Check .env is not in git
git status
```
**Pass criteria:** `.env` in `.gitignore`, not tracked

### **‚úÖ Module 0.3 - Deployment Gate**
**Pass criteria:** Will deploy to Render/Railway after testing

### **‚úÖ Module 0.4 - Executable System Gate**
```powershell
# Verify multi-stage Dockerfile
Get-Content Dockerfile | Select-String "FROM python" 

# Verify PostgreSQL in docker-compose
docker-compose ps
```
**Pass criteria:** 
- ‚úÖ Multi-stage Dockerfile (2 FROM statements)
- ‚úÖ PostgreSQL service running
- ‚úÖ Auto-ingest on startup (check logs)

### **‚úÖ Module 2 - Normalization Gate**
```powershell
# Check for canonical_id in data
(Invoke-WebRequest -Uri "http://localhost:8000/api/v1/data?page_size=1" -UseBasicParsing).Content | ConvertFrom-Json
```
**Pass criteria:**
- ‚úÖ Records have `canonical_id` field
- ‚úÖ No duplicates (BTC appears only once)

---

## **üîπ Step 8: Cleanup**

### **Stop Services**
```powershell
.\run.ps1 down

# OR
docker-compose down
```

### **Clean Everything (Including Volumes)**
```powershell
.\run.ps1 clean

# OR
docker-compose down -v
```

---

## **‚úÖ Success Criteria Checklist**

- [ ] CSV file generated successfully
- [ ] Local server starts without errors
- [ ] Auto-ingest works on startup
- [ ] All 3 data sources ingest successfully
- [ ] Health endpoint returns `status: "healthy"`
- [ ] Data has `canonical_id` field
- [ ] No duplicate coins (same symbol only once)
- [ ] PostgreSQL service running
- [ ] Docker services start successfully
- [ ] Multi-stage Dockerfile builds
- [ ] Tests pass
- [ ] API documentation accessible at `/docs`

---

## **üêõ Troubleshooting**

### **CSV file not found**
```powershell
python scripts\generate_sample_csv.py
```

### **Port 8000 already in use**
```powershell
# Find and kill process
netstat -ano | findstr :8000
taskkill /PID <PID> /F
```

### **PostgreSQL connection error**
```powershell
# Check if PostgreSQL is running
docker-compose ps postgres

# Restart PostgreSQL
docker-compose restart postgres
```

### **Module import errors**
```powershell
# Reinstall in development mode
pip install -e .
```

---

## **üìä Next Steps After Testing**

1. ‚úÖ All tests pass ‚Üí Deploy to Render/Railway
2. ‚úÖ Push to GitHub
3. ‚úÖ Create deployment documentation
4. ‚úÖ Submit assignment with live URLs

---

**Need help? Check logs:**
```powershell
# Local logs
# (visible in terminal where uvicorn is running)

# Docker logs
.\run.ps1 logs
```
